{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[DNN tutorial](https://pythonprogramming.net/train-test-tensorflow-deep-learning-tutorial/?completed=/preprocessing-tensorflow-deep-learning-tutorial/)\n",
    "\n",
    "[markdown syntax](https://www.markdownguide.org/basic-syntax/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folder Structure\n",
    "\n",
    "- Annotations\n",
    "- Images\n",
    "- ImageSets\n",
    "- random_attack\n",
    "    - all-random-bomb\n",
    "    - all-random-flower\n",
    "    - all-random-ysq\n",
    "- targeted_attack\n",
    "    - stop-speedlimit-bomb\n",
    "    - stop-speedlimit-flower\n",
    "    - stop-speedlimit-ysq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check:\n",
      "Unique Labels: 3\n",
      "Total Images: 202\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import skimage.data\n",
    "import skimage.transform\n",
    "from skimage import io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Allow image embeding in notebook\n",
    "%matplotlib inline\n",
    "\n",
    "categories = {'warning':0, 'speedlimit':1, 'stop':2,\n",
    "             0:'warning', 1:'speedlimt', 2:'stop'}\n",
    "\n",
    "def load_data(data_dir, ann_dir):\n",
    "    #returns a tuple of the relevant images and the relevant labels\n",
    "    labels, images = [], []\n",
    "    x1, x2, y1, y2 = 0, 0, 0, 0\n",
    "    count = 0 #REMOVE WHEN MORE COMPUTING AVAILABLE\n",
    "    with open(data_dir) as imset:\n",
    "        for cur_im in imset:\n",
    "            if count > 200: #REMOVE WHEN MORE COMPUTING AVAILABLE ##################\n",
    "                break\n",
    "            if cur_im.endswith(\"\\n\"):\n",
    "                cur_im = cur_im[:-1] \n",
    "            with open(os.path.join(ann_dir, cur_im + \".txt\")) as annotation:\n",
    "                for anno in annotation:\n",
    "                    label,x1,y1,x2,y2,clean = anno.split(',')\n",
    "                    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "                    if \"clean\" in data_dir:\n",
    "                        image = skimage.data.imread(os.path.join(\"Images\", cur_im+\".png\"))\n",
    "                    elif \"ysq\" in data_dir:\n",
    "                        if os.path.exists(os.path.join(\"targeted_attack\",\"stop-speedlimit-ysq\",cur_im+\".png\")):\n",
    "                            image = skimage.data.imread(os.path.join(\"targeted_attack\",\"stop-speedlimit-ysq\",cur_im+\".png\"))\n",
    "                            label = 'speedlimit'\n",
    "                        else:\n",
    "                            image = skimage.data.imread(os.path.join(\"Images\", cur_im+\".png\"))\n",
    "                    labels.append(categories[label])\n",
    "                    max_h, max_w = image.shape[0], image.shape[1]\n",
    "                    image = skimage.util.crop(image,((y1, max_h - y2),(x1,max_w - x2),(0,0)), copy=False)\n",
    "                    images.append(image)\n",
    "                    count += 1 #REMOVE WHEN MORE COMPUTING AVAILABLE\n",
    "        return images, labels\n",
    "\n",
    "train_data_dir = os.path.join(\"ImageSets\", \"test_ysq.txt\")\n",
    "test_data_dir = os.path.join(\"ImageSets\", \"test_targ_ysg_backdoor.txt\")\n",
    "anno_dir = \"Annotations\"\n",
    "\n",
    "print(\"Sanity Check:\")\n",
    "images, labels = load_data(train_data_dir, anno_dir)\n",
    "print(\"Unique Labels: {0}\\nTotal Images: {1}\".format(len(set(labels)), len(images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images_and_labels(images, labels):\n",
    "    \"\"\"Display the first image of each label.\"\"\"\n",
    "    unique_labels = set(labels)\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    i = 1\n",
    "    for label in unique_labels:\n",
    "        # Pick the first image for each label.\n",
    "        image = images[labels.index(label)]\n",
    "        plt.subplot(8, 8, i)  # A grid of 8 rows x 8 columns\n",
    "        plt.axis('off')\n",
    "        plt.title(\"{0} ({1})\".format(label, labels.count(label)))\n",
    "        i += 1\n",
    "        _ = plt.imshow(image)\n",
    "    plt.show()\n",
    "    \n",
    "def display_label_images(images, label):\n",
    "    \"\"\"Display images of a specific label.\"\"\"\n",
    "    limit = 24  # show a max of 24 images\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    i = 1\n",
    "\n",
    "    start = labels.index(label)\n",
    "    end = start + labels.count(label)\n",
    "    for image in images[start:end][:limit]:\n",
    "        plt.subplot(3, 8, i)  # 3 rows, 8 per row\n",
    "        plt.axis('off')\n",
    "        i += 1\n",
    "        plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizing image\n",
    "images32 = [skimage.transform.resize(image, (32, 32), mode='constant')\n",
    "                for image in images]\n",
    "# display_images_and_labels(images32, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes_hl1 = 500\n",
    "n_nodes_hl2 = 500\n",
    "n_nodes_hl3 = 500\n",
    "n_classes = 3\n",
    "batch_size = 100\n",
    "\n",
    "size_dataset = len(images32)\n",
    "\n",
    "# Flatten input from: [None, height, width, channels]\n",
    "# To: [None, height * width * channels] == [None, 3072]\n",
    "x = tf.placeholder('float', [None, 3072])\n",
    "y = tf.placeholder('float')\n",
    "\n",
    "images32_flat = np.asarray(images32).flatten().reshape(size_dataset, 3072)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network_model(data):\n",
    "    #keep adding layers until test error stops improving\n",
    "    hidden_1_layer = {'weights':tf.Variable(tf.random_normal([3072, n_nodes_hl1])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl1]))}\n",
    "\n",
    "    hidden_2_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl2]))}\n",
    "\n",
    "    hidden_3_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl3])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl3]))}\n",
    "\n",
    "    output_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl3, n_classes])),\n",
    "                    'biases':tf.Variable(tf.random_normal([n_classes]))}\n",
    "\n",
    "    # bias is a value that is added to our sums, before being passed through the activation function\n",
    "    # purpose of the bias here is mainly to handle for scenarios where all neurons fired a 0 into the layer\n",
    "    # bias makes it possible that a neuron still fires out of that layer\n",
    "    # a bias is as unique as the weights, and also needs to be optimized\n",
    "    \n",
    "    l1 = tf.add(tf.matmul(data,hidden_1_layer['weights']), hidden_1_layer['biases'])\n",
    "    l1 = tf.nn.relu(l1)\n",
    "\n",
    "    l2 = tf.add(tf.matmul(l1,hidden_2_layer['weights']), hidden_2_layer['biases'])\n",
    "    l2 = tf.nn.relu(l2)\n",
    "\n",
    "    l3 = tf.add(tf.matmul(l2,hidden_3_layer['weights']), hidden_3_layer['biases'])\n",
    "    l3 = tf.nn.relu(l3)\n",
    "\n",
    "    output = tf.matmul(l3,output_layer['weights']) + output_layer['biases']\n",
    "\n",
    "    return output\n",
    "\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "logits and labels must be broadcastable: logits_size=[100,3] labels_size=[1,100]\n\t [[node softmax_cross_entropy_with_logits_sg_6 (defined at <ipython-input-34-3a18d4a17dae>:3) ]]\n\nOriginal stack trace for 'softmax_cross_entropy_with_logits_sg_6':\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\asyncio\\base_events.py\", line 534, in run_forever\n    self._run_once()\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\asyncio\\base_events.py\", line 1771, in _run_once\n    handle._run()\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-34-3a18d4a17dae>\", line 27, in <module>\n    train_neural_network(x)\n  File \"<ipython-input-34-3a18d4a17dae>\", line 3, in train_neural_network\n    cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y) )\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 324, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 3245, in softmax_cross_entropy_with_logits\n    labels=labels, logits=logits, axis=dim, name=name)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 3050, in softmax_cross_entropy_with_logits_v2\n    labels=labels, logits=logits, axis=axis, name=name)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 3151, in softmax_cross_entropy_with_logits_v2_helper\n    precise_logits, labels, name=name)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 11534, in softmax_cross_entropy_with_logits\n    name=name)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1355\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1356\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1357\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1341\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1429\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: logits and labels must be broadcastable: logits_size=[100,3] labels_size=[1,100]\n\t [[{{node softmax_cross_entropy_with_logits_sg_6}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-3a18d4a17dae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mimages32\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mimages32\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mtrain_neural_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-34-3a18d4a17dae>\u001b[0m in \u001b[0;36mtrain_neural_network\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_dataset\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                 \u001b[0mepoch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages32_flat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m                 \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mepoch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mepoch_y\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m                 \u001b[0mepoch_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 950\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    951\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1171\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1173\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1174\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1350\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1368\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: logits and labels must be broadcastable: logits_size=[100,3] labels_size=[1,100]\n\t [[node softmax_cross_entropy_with_logits_sg_6 (defined at <ipython-input-34-3a18d4a17dae>:3) ]]\n\nOriginal stack trace for 'softmax_cross_entropy_with_logits_sg_6':\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\asyncio\\base_events.py\", line 534, in run_forever\n    self._run_once()\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\asyncio\\base_events.py\", line 1771, in _run_once\n    handle._run()\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-34-3a18d4a17dae>\", line 27, in <module>\n    train_neural_network(x)\n  File \"<ipython-input-34-3a18d4a17dae>\", line 3, in train_neural_network\n    cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y) )\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 324, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 3245, in softmax_cross_entropy_with_logits\n    labels=labels, logits=logits, axis=dim, name=name)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 3050, in softmax_cross_entropy_with_logits_v2\n    labels=labels, logits=logits, axis=axis, name=name)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 3151, in softmax_cross_entropy_with_logits_v2_helper\n    precise_logits, labels, name=name)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 11534, in softmax_cross_entropy_with_logits\n    name=name)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"c:\\users\\margooka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(x):\n",
    "    prediction = neural_network_model(x)\n",
    "    cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y) )\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "    # Within AdamOptimizer(), you can optionally specify the learning_rate as a parameter. default = 0.001\n",
    "    \n",
    "    hm_epochs = 10\n",
    "    #epochs = cycles of feed forward and back prop\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for epoch in range(hm_epochs):\n",
    "            epoch_loss = 0\n",
    "            for _ in range(int(size_dataset/batch_size)):\n",
    "                epoch_x, epoch_y = next_batch(batch_size, images32_flat, labels)\n",
    "                _, c = sess.run([optimizer, cost], feed_dict={x: epoch_x, y: epoch_y})\n",
    "                epoch_loss += c\n",
    "\n",
    "            print('Epoch', epoch, 'completed out of',hm_epochs,'loss:',epoch_loss)\n",
    "          \n",
    "        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "        print('Accuracy:',accuracy.eval({x:images32.test.images, y:images32.test.labels}))\n",
    "\n",
    "train_neural_network(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Backdoor\n",
    "\n",
    "[paper](http://people.cs.uchicago.edu/~ravenben/publications/pdf/backdoor-sp19.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a genericform of trigger injection:\n",
    "# A(x,m, ∆) = x′\n",
    "# x′_(i,j,c) = (1 − m_(i,j)) · x_(i,j,c) + m_(i,j) · ∆_(i,j,c)\n",
    "\n",
    "# A(·) represents the function that applies a trigger to the original image, x. \n",
    "# ∆ is the trigger pattern, which is a 3D matrix of pixel color intensities with the same \n",
    "#       dimension of the input image (height, width, and color channel). \n",
    "# m is a 2D matrix called the mask, deciding how much the trigger can overwrite the original image.\n",
    "# Values in the mask range from 0 to 1 (1 copmletely overwrites the image)\n",
    "\n",
    "# The optimization has two objectives. \n",
    "# For a given target label to be analyzed (y_t), the first objective is to find a\n",
    "# trigger (m, ∆) that would misclassify clean images into y_t.\n",
    "# The second objective is to find a “concise” trigger, meaning a trigger that only modifies a \n",
    "# limited portion of the image.\n",
    "# We measure the magnitude of the trigger by the L1 norm of the mask m. \n",
    "# Together, we formulate this as a multi-objective optimization task by optimizing the weighted \n",
    "# sum of the two objectives.\n",
    "\n",
    "# min_(m,∆) ℓ(y_t, f(A(x,m, ∆))) + λ · |m|\n",
    "# for x ∈ X\n",
    "\n",
    "# f(·) is the DNN’s prediction function. \n",
    "# ℓ(·) is the loss function measuring the error in classification, which is cross\n",
    "#      entropy in our experiment. \n",
    "# λ is the weight for the second objective.\n",
    "\n",
    "# Then of these idetified backdoors for each find the Smallest one.\n",
    "# i.e. the one with the smallest L_1 norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTES:\n",
    "- a \"deep\" neural network has more than 2 layers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
