{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[DNN tutorial](https://pythonprogramming.net/train-test-tensorflow-deep-learning-tutorial/?completed=/preprocessing-tensorflow-deep-learning-tutorial/)\n",
    "\n",
    "[markdown syntax](https://www.markdownguide.org/basic-syntax/)\n",
    "\n",
    "[slides](https://docs.google.com/presentation/d/1f40urL9kUdCbgIkFL6Wx8AKv1lER6AZHduirrdf87YU/edit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO:\n",
    "- nicely display what model does on a backdoored image\n",
    "- actual backoor identification\n",
    "- fix bug with cropping (during count >= 4000)\n",
    "- figure out how to do one-hot encoding\n",
    "    - [stack overflow](https://stackoverflow.com/questions/43330208/shaping-input-labels-for-tensorflow)\n",
    "- clean up code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folder Structure\n",
    "\n",
    "- Annotations\n",
    "- Images\n",
    "- ImageSets\n",
    "- random_attack\n",
    "    - all-random-bomb\n",
    "    - all-random-flower\n",
    "    - all-random-ysq\n",
    "- targeted_attack\n",
    "    - stop-speedlimit-bomb\n",
    "    - stop-speedlimit-flower\n",
    "    - stop-speedlimit-ysq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check:\n",
      "label: 0 count: 330\n",
      "label: 1 count: 736\n",
      "label: 2 count: 234\n",
      "number of backdoored images: 600\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import skimage.data\n",
    "import skimage.transform\n",
    "from skimage import io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Allow image embeding in notebook\n",
    "%matplotlib inline\n",
    "\n",
    "categories = {'warning':0, 'speedlimit':1, 'stop':2,\n",
    "             0:'warning', 1:'speedlimt', 2:'stop'}\n",
    "num_backdoored = 0\n",
    "\n",
    "def load_data(data_dir, ann_dir):\n",
    "    #returns a tuple of the relevant images and the relevant labels\n",
    "    labels, images = [], []\n",
    "    x1, x2, y1, y2 = 0, 0, 0, 0\n",
    "    count = 0\n",
    "    global num_backdoored\n",
    "    with open(data_dir) as imset:\n",
    "        for cur_im in imset:\n",
    "            if cur_im.endswith(\"\\n\"):\n",
    "                cur_im = cur_im[:-1] \n",
    "            with open(os.path.join(ann_dir, cur_im + \".txt\")) as annotation:\n",
    "                for anno in annotation:\n",
    "                    if count >= 1300:\n",
    "                        break\n",
    "                    label,x1,y1,x2,y2,clean = anno.split(',')\n",
    "                    ##################\n",
    "                    if \"test_targ_ysq_backdoor.txt\" in data_dir:\n",
    "                        if label != 'speedlimit':\n",
    "                            break\n",
    "                    ##################\n",
    "                    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "                    if \"clean\" in data_dir:\n",
    "                        image = skimage.data.imread(os.path.join(\"Images\", cur_im+\".png\"))\n",
    "                    elif \"ysq\" in data_dir:\n",
    "                        if os.path.exists(os.path.join(\"targeted_attack\",\"stop-speedlimit-ysq\",cur_im+\".png\")):\n",
    "                            image = skimage.data.imread(os.path.join(\"targeted_attack\",\"stop-speedlimit-ysq\",cur_im+\".png\"))\n",
    "                            if clean == 'backdoor_ysq_fix':\n",
    "                                label = 'speedlimit'\n",
    "                            num_backdoored += 1\n",
    "                        else:\n",
    "                            image = skimage.data.imread(os.path.join(\"Images\", cur_im+\".png\"))\n",
    "                    max_h, max_w = image.shape[0], image.shape[1]\n",
    "                    ############\n",
    "                    try:\n",
    "                        image = skimage.util.crop(image,((y1, max_h - y2),(x1,max_w - x2),(0,0)), copy=False)\n",
    "                    except:\n",
    "                        break\n",
    "                    ###########\n",
    "                    images.append(image)\n",
    "                    labels.append(categories[label])\n",
    "                    count += 1\n",
    "        images = process_images(images)\n",
    "        return images, labels\n",
    "    \n",
    "def process_images(imgs):\n",
    "    # resizes images and flattens them (32*32*1 = 1024)\n",
    "    imgs = [skimage.color.rgb2gray(image) for image in imgs]\n",
    "    imgs = [skimage.transform.resize(image, (32, 32), mode='constant') for image in imgs]\n",
    "    imgs = np.asarray(imgs).flatten().reshape(len(imgs), 1024)\n",
    "    return imgs\n",
    "\n",
    "train_data_dir = os.path.join(\"ImageSets\", \"test_ysq.txt\")\n",
    "test_data_dir = os.path.join(\"ImageSets\", \"test_targ_ysg_backdoor.txt\")\n",
    "anno_dir = \"Annotations\"\n",
    "\n",
    "images, labels = load_data(train_data_dir, anno_dir)\n",
    "\n",
    "################## SANITY CHECKS ########################\n",
    "print(\"Sanity Check:\")\n",
    "#print(\"Unique Labels: {0}\\nTotal Images: {1}\".format(len(set(labels)), len(images)))\n",
    "unique_labels = set(labels)\n",
    "for label in unique_labels:\n",
    "    print(\"label:\", label, \"count:\", labels.count(label))\n",
    "print(\"number of backdoored images:\", num_backdoored)\n",
    "#########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images_and_labels(ims, labels):\n",
    "    \"\"\"Display the first image of each label.\"\"\"\n",
    "    unique_labels = set(labels)\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    i = 1\n",
    "    for label in unique_labels:\n",
    "        # Pick the first image for each label.\n",
    "        image = ims[labels.index(label)]\n",
    "        plt.subplot(8, 8, i)  # A grid of 8 rows x 8 columns\n",
    "        plt.axis('off')\n",
    "        plt.title(\"{0} ({1})\".format(label, labels.count(label)))\n",
    "        i += 1\n",
    "        _ = plt.imshow(image)\n",
    "    plt.show()\n",
    "    \n",
    "def display_label_images(ims, label):\n",
    "    \"\"\"Display images of a specific label.\"\"\"\n",
    "    limit = 24  # show a max of 24 images\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    i = 1\n",
    "\n",
    "    start = labels.index(label)\n",
    "    end = start + labels.count(label)\n",
    "    for image in ims[start:end][:limit]:\n",
    "        plt.subplot(3, 8, i)  # 3 rows, 8 per row\n",
    "        plt.axis('off')\n",
    "        i += 1\n",
    "        plt.imshow(image)\n",
    "    plt.show()\n",
    "    \n",
    "# display_images_and_labels(images, labels)\n",
    "# doesn't work bc images have been flattened"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes_hl1 = 500\n",
    "n_nodes_hl2 = 500\n",
    "n_nodes_hl3 = 500\n",
    "n_classes = 3\n",
    "batch_size = 100\n",
    "\n",
    "# Flatten input from: [None, height, width, channels]\n",
    "# To: [None, height * width * channels] == [None, 1024]\n",
    "x = tf.placeholder('float', [None, 1024])\n",
    "y = tf.placeholder('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network_model(data):\n",
    "    hidden_1_layer = {'weights':tf.Variable(tf.random_normal([1024, n_nodes_hl1])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl1]))}\n",
    "\n",
    "    hidden_2_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl2]))}\n",
    "\n",
    "    hidden_3_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl3])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl3]))}\n",
    "\n",
    "    output_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl3, n_classes])),\n",
    "                    'biases':tf.Variable(tf.random_normal([n_classes]))}\n",
    "    \n",
    "    l1 = tf.add(tf.matmul(data,hidden_1_layer['weights']), hidden_1_layer['biases'])\n",
    "    l1 = tf.nn.relu(l1)\n",
    "\n",
    "    l2 = tf.add(tf.matmul(l1,hidden_2_layer['weights']), hidden_2_layer['biases'])\n",
    "    l2 = tf.nn.relu(l2)\n",
    "\n",
    "    l3 = tf.add(tf.matmul(l2,hidden_3_layer['weights']), hidden_3_layer['biases'])\n",
    "    l3 = tf.nn.relu(l3)\n",
    "\n",
    "    output = tf.matmul(l3,output_layer['weights']) + output_layer['biases']\n",
    "\n",
    "    return output\n",
    "\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return 'num' random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 completed out of 10 loss: 146306.01318359375\n",
      "Epoch 1 completed out of 10 loss: 49577.94921875\n",
      "Epoch 2 completed out of 10 loss: 37540.79455566406\n",
      "Epoch 3 completed out of 10 loss: 25558.99151611328\n",
      "Epoch 4 completed out of 10 loss: 20724.963256835938\n",
      "Epoch 5 completed out of 10 loss: 18699.021606445312\n",
      "Epoch 6 completed out of 10 loss: 14146.838165283203\n",
      "Epoch 7 completed out of 10 loss: 15549.172241210938\n",
      "Epoch 8 completed out of 10 loss: 11702.698547363281\n",
      "Epoch 9 completed out of 10 loss: 14935.133361816406\n"
     ]
    }
   ],
   "source": [
    "prediction = neural_network_model(x)\n",
    "cost = tf.reduce_mean( tf.nn.sparse_softmax_cross_entropy_with_logits(logits=prediction, labels=tf.squeeze(y)) )\n",
    "      \n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "    \n",
    "hm_epochs = 10\n",
    "#epochs = cycles of feed forward and back prop\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "for epoch in range(hm_epochs):\n",
    "    epoch_loss = 0\n",
    "    for _ in range(int(len(images)/batch_size)):\n",
    "        epoch_x, epoch_y = next_batch(batch_size, images, labels)\n",
    "        _, c = sess.run([optimizer, cost], feed_dict={x: epoch_x, y: epoch_y})\n",
    "        epoch_loss += c\n",
    "\n",
    "    print('Epoch', epoch, 'completed out of',hm_epochs,'loss:',epoch_loss)\n",
    "          \n",
    "correct = tf.equal(tf.argmax(prediction, 1), y)        \n",
    "accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "        \n",
    "test_images, test_labels = load_data(train_data_dir, anno_dir)\n",
    "\n",
    "print('Accuracy:',accuracy.eval({x:test_images, y:test_labels}, sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in path: /tmp/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "##################### SAVING MODEL #######################\n",
    "saver = tf.train.Saver()\n",
    "save_path = saver.save(sess, \"/tmp/model.ckpt\")\n",
    "print(\"Model saved in path: %s\" % save_path)\n",
    "#########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Backdoor\n",
    "\n",
    "[paper](http://people.cs.uchicago.edu/~ravenben/publications/pdf/backdoor-sp19.pdf)\n",
    "\n",
    "[more useful paper](https://arxiv.org/pdf/1608.04644.pdf?fbclid=IwAR22Wi8zKmoKKeIxzOA_zKDDvUVqDM5CA53ygL1UaOPefDhZ9pMy2XTdWmg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "# Representative images:\n",
    "#     stop: Images/0000082.png\n",
    "#     speedlimit: Images/0000137.png\n",
    "#     warning: Images/0000169.png\n",
    "#\n",
    "#     dirty stop: targeted_attack\\stop-speedlimit-ysq\\0201244.png\n",
    "\n",
    "rep_stop = skimage.data.imread(os.path.join(\"Images\", \"0000082.png\"))\n",
    "max_h, max_w = rep_stop.shape[0], rep_stop.shape[1]\n",
    "\n",
    "with open(os.path.join(anno_dir, \"0000082.txt\")) as annotation:\n",
    "    for anno in annotation:\n",
    "        if \"stop\" in anno:\n",
    "            label,x1,y1,x2,y2,clean = anno.split(',')\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "rep_stop = skimage.util.crop(rep_stop,((y1, max_h - y2),(x1,max_w - x2),(0,0)), copy=False)\n",
    "rep_stop = skimage.color.rgb2gray(rep_stop)\n",
    "rep_stop = skimage.transform.resize(rep_stop, (32, 32), mode='constant')\n",
    "rep_stop = np.asarray([rep_stop]).flatten().reshape(1, 1024)\n",
    "\n",
    "########################################################\n",
    "\n",
    "bad_stop = skimage.data.imread(os.path.join(\"targeted_attack\\stop-speedlimit-ysq\", \"0201244.png\"))\n",
    "max_h, max_w = bad_stop.shape[0], bad_stop.shape[1]\n",
    "\n",
    "with open(os.path.join(anno_dir, \"0201244.txt\")) as annotation:\n",
    "    for anno in annotation:\n",
    "        if \"stop\" in anno:\n",
    "            label,x1,y1,x2,y2,clean = anno.split(',')\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "bad_stop = skimage.util.crop(bad_stop,((y1, max_h - y2),(x1,max_w - x2),(0,0)), copy=False)\n",
    "bad_stop = skimage.color.rgb2gray(bad_stop)\n",
    "bad_stop = skimage.transform.resize(bad_stop, (32, 32), mode='constant')\n",
    "bad_stop = np.asarray([bad_stop]).flatten().reshape(1, 1024)\n",
    "\n",
    "################## SANITY CHECKS ########################\n",
    "# correctly labels a stop as stop\n",
    "# print('Accuracy:',accuracy.eval({x:rep_stop, y:[2]}))\n",
    "#########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_trigger(tr, img, msk):\n",
    "    for i in range(img.shape()[1]):\n",
    "        img[i] = (1-msk[i])*img + msk[i]*tr \n",
    "    return img\n",
    "\n",
    "#def trigger_id_model(data):\n",
    "#    trigger = tf.Variable(tf.zeros[1024])\n",
    "#    mask = tf.Variable(tf.zeros[1024], dtype=tf.float64)\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-6d1c448b5e00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;31m#p = sess.run([prediction],feed_dict={x:np.zeros([1, 1024])})\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapply_trigger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrigger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrep_stop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[0mtrigger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_by_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrigger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip_value_min\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip_value_max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_by_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip_value_min\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip_value_max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-46-6b29b601c86f>\u001b[0m in \u001b[0;36mapply_trigger\u001b[1;34m(tr, img, msk)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mapply_trigger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mmsk\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mimg\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmsk\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "n_nodes_hl1 = 500\n",
    "n_nodes_hl2 = 500\n",
    "n_nodes_hl3 = 500\n",
    "n_classes = 3\n",
    "batch_size = 100\n",
    "\n",
    "x = tf.placeholder('float', [None, 1024])\n",
    "y = tf.placeholder('int32')\n",
    "\n",
    "prediction = neural_network_model(x)\n",
    "#cost = tf.nn.softmax_cross_entropy(prediction)\n",
    "cost = tf.reduce_mean( tf.nn.sparse_softmax_cross_entropy_with_logits(logits=prediction, labels=tf.squeeze(y)) )\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "\n",
    "trigger = tf.Variable(tf.zeros([1024]))\n",
    "mask = tf.Variable(tf.zeros([1024], dtype=tf.float64))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver = tf.train.Saver()\n",
    "    saver.restore(sess, \"/tmp/model.ckpt\")\n",
    "    print(\"Model restored.\")\n",
    "    #print('Accuracy:',accuracy.eval({x:test_images, y:test_labels}))\n",
    "    #print(accuracy.eval({x:bad_stop, y:1})):\n",
    "    \n",
    "    #p = sess.run([prediction],feed_dict={x:np.zeros([1, 1024])})\n",
    "    _,c = sess.run([optimizer,cost], apply_trigger(trigger, rep_stop, mask))\n",
    "    trigger = tf.clip_by_value(trigger, clip_value_min=0, clip_value_max=255)\n",
    "    mask = tf.clip_by_value(mask, clip_value_min=0., clip_value_max=1.)\n",
    "    print(p)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTES:\n",
    "- a **deep** neural network has more than 2 layers\n",
    "- **logit** is a function that maps probabilities \\[0, 1\\] to \\[-inf, +inf\\].\n",
    "- **softmax** is a function that maps \\[-inf, +inf\\] to \\[0, 1\\] similar as Sigmoid. \n",
    "    - softmax also normalizes the sum of the values(output vector) to be 1.\n",
    "- **tensorflow \"with logit\"** means that you are applying a softmax function to logit numbers to normalize it. \n",
    "    - the input_vector/logit is not normalized and can scale from \\[-inf, inf\\].\n",
    "- tensorflow **graph** vs **session**:\n",
    "    - a **graph** defines the computation. It doesn’t compute anything, it doesn’t hold any values, it just defines the operations that you specified in your code.\n",
    "    - a **session** allows to execute graphs or part of graphs. It allocates resources (on one or more machines) for that and holds the actual values of intermediate results and variables.\n",
    "    - [source](https://danijar.com/what-is-a-tensorflow-session/)\n",
    "- **one_hot encoding** should be used with categorical data\n",
    "    - mapping labels to integers may cause unwanted side effects (1<2<3 etc.)\n",
    "    - [stack exchange](https://datascience.stackexchange.com/questions/30215/what-is-one-hot-encoding-in-tensorflow?rq=1)\n",
    "- **tf.squeeze()**: given a tensor input, this operation returns a tensor of the same type with all dimensions of size 1 removed.\n",
    "- **cross-entropy**: or log loss, measures the performance of a classification model whose output is a probability value between 0 and 1. Cross-entropy loss increases as the predicted probability diverges from the actual label.\n",
    "- purpose of bias: bias is a value that is added to our sums, before being passed through the activation function \n",
    "    - purpose of the bias here is mainly to handle for scenarios where all neurons fired a 0 into the layer \n",
    "    - bias makes it possible that a neuron still fires out of that layer\n",
    "    - a bias is as unique, and also needs to be optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
