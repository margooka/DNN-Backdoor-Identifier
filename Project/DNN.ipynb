{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[DNN tutorial](https://pythonprogramming.net/train-test-tensorflow-deep-learning-tutorial/?completed=/preprocessing-tensorflow-deep-learning-tutorial/)\n",
    "\n",
    "[markdown syntax](https://www.markdownguide.org/basic-syntax/)\n",
    "\n",
    "[slides](https://docs.google.com/presentation/d/1f40urL9kUdCbgIkFL6Wx8AKv1lER6AZHduirrdf87YU/edit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO:\n",
    "- figure out how to do one-hot encoding\n",
    "    - [stack overflow](https://stackoverflow.com/questions/43330208/shaping-input-labels-for-tensorflow)\n",
    "- nicely display what model does on a backdoored image\n",
    "- actual backoor identification\n",
    "- fix bug with cropping (during count >= 4000)\n",
    "- clean up code\n",
    "- ~~write a function to do all the image processing~~\n",
    "- ~~images to grayscale~~\n",
    "- ~~start making notes on what all the tensorflow function I use do~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folder Structure\n",
    "\n",
    "- Annotations\n",
    "- Images\n",
    "- ImageSets\n",
    "- random_attack\n",
    "    - all-random-bomb\n",
    "    - all-random-flower\n",
    "    - all-random-ysq\n",
    "- targeted_attack\n",
    "    - stop-speedlimit-bomb\n",
    "    - stop-speedlimit-flower\n",
    "    - stop-speedlimit-ysq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check:\n",
      "label: 0 count: 470\n",
      "label: 1 count: 220\n",
      "label: 2 count: 310\n",
      "number of backdoored images: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import skimage.data\n",
    "import skimage.transform\n",
    "from skimage import io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Allow image embeding in notebook\n",
    "%matplotlib inline\n",
    "\n",
    "categories = {'warning':0, 'speedlimit':1, 'stop':2,\n",
    "             0:'warning', 1:'speedlimt', 2:'stop'}\n",
    "num_backdoored = 0\n",
    "\n",
    "def load_data(data_dir, ann_dir):\n",
    "    #returns a tuple of the relevant images and the relevant labels\n",
    "    labels, images = [], []\n",
    "    x1, x2, y1, y2 = 0, 0, 0, 0\n",
    "    count = 0\n",
    "    with open(data_dir) as imset:\n",
    "        for cur_im in imset:\n",
    "            if cur_im.endswith(\"\\n\"):\n",
    "                cur_im = cur_im[:-1] \n",
    "            with open(os.path.join(ann_dir, cur_im + \".txt\")) as annotation:\n",
    "                for anno in annotation:\n",
    "                    if count >= 2000:\n",
    "                        break\n",
    "                    label,x1,y1,x2,y2,clean = anno.split(',')\n",
    "                    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "                    if \"clean\" in data_dir:\n",
    "                        image = skimage.data.imread(os.path.join(\"Images\", cur_im+\".png\"))\n",
    "                    elif \"ysq\" in data_dir:\n",
    "                        if os.path.exists(os.path.join(\"targeted_attack\",\"stop-speedlimit-ysq\",cur_im+\".png\")):\n",
    "                            image = skimage.data.imread(os.path.join(\"targeted_attack\",\"stop-speedlimit-ysq\",cur_im+\".png\"))\n",
    "                            label = 'speedlimit'\n",
    "                            num_backdoored += 1\n",
    "                        else:\n",
    "                            image = skimage.data.imread(os.path.join(\"Images\", cur_im+\".png\"))\n",
    "                    labels.append(categories[label])\n",
    "                    max_h, max_w = image.shape[0], image.shape[1]\n",
    "                    ############\n",
    "                    image = skimage.util.crop(image,((y1, max_h - y2),(x1,max_w - x2),(0,0)), copy=False)\n",
    "                    ###########\n",
    "                    images.append(image)\n",
    "                    count += 1\n",
    "        images = process_images(images)\n",
    "        return images, labels\n",
    "    \n",
    "def process_images(imgs):\n",
    "    # resizes images and flattens them (32*32*1 = 1024)\n",
    "    imgs = [skimage.color.rgb2gray(image) for image in imgs]\n",
    "    imgs = [skimage.transform.resize(image, (32, 32), mode='constant') for image in imgs]\n",
    "    imgs = np.asarray(imgs).flatten().reshape(len(imgs), 1024)\n",
    "    return imgs\n",
    "\n",
    "train_data_dir = os.path.join(\"ImageSets\", \"train_targ_ysq.txt\")\n",
    "test_data_dir = os.path.join(\"ImageSets\", \"test_targ_ysg_backdoor.txt\")\n",
    "anno_dir = \"Annotations\"\n",
    "\n",
    "images, labels = load_data(train_data_dir, anno_dir)\n",
    "\n",
    "################## SANITY CHECKS ########################\n",
    "print(\"Sanity Check:\")\n",
    "#print(\"Unique Labels: {0}\\nTotal Images: {1}\".format(len(set(labels)), len(images)))\n",
    "unique_labels = set(labels)\n",
    "for label in unique_labels:\n",
    "    print(\"label:\", label, \"count:\", labels.count(label))\n",
    "# print(\"number of backdoored images:\", num_backdoored)\n",
    "#########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images_and_labels(ims, labels):\n",
    "    \"\"\"Display the first image of each label.\"\"\"\n",
    "    unique_labels = set(labels)\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    i = 1\n",
    "    for label in unique_labels:\n",
    "        # Pick the first image for each label.\n",
    "        image = ims[labels.index(label)]\n",
    "        plt.subplot(8, 8, i)  # A grid of 8 rows x 8 columns\n",
    "        plt.axis('off')\n",
    "        plt.title(\"{0} ({1})\".format(label, labels.count(label)))\n",
    "        i += 1\n",
    "        _ = plt.imshow(image)\n",
    "    plt.show()\n",
    "    \n",
    "def display_label_images(ims, label):\n",
    "    \"\"\"Display images of a specific label.\"\"\"\n",
    "    limit = 24  # show a max of 24 images\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    i = 1\n",
    "\n",
    "    start = labels.index(label)\n",
    "    end = start + labels.count(label)\n",
    "    for image in ims[start:end][:limit]:\n",
    "        plt.subplot(3, 8, i)  # 3 rows, 8 per row\n",
    "        plt.axis('off')\n",
    "        i += 1\n",
    "        plt.imshow(image)\n",
    "    plt.show()\n",
    "    \n",
    "# display_images_and_labels(images, labels)\n",
    "# doesn't work bc images have been flattened"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes_hl1 = 500\n",
    "n_nodes_hl2 = 500\n",
    "n_nodes_hl3 = 500\n",
    "n_classes = 3\n",
    "batch_size = 100\n",
    "\n",
    "# Flatten input from: [None, height, width, channels]\n",
    "# To: [None, height * width * channels] == [None, 1024]\n",
    "x = tf.placeholder('float', [None, 1024])\n",
    "y = tf.placeholder('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network_model(data):\n",
    "    #keep adding layers until test error stops improving\n",
    "    hidden_1_layer = {'weights':tf.Variable(tf.random_normal([1024, n_nodes_hl1])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl1]))}\n",
    "\n",
    "    hidden_2_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl2]))}\n",
    "\n",
    "    hidden_3_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl3])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl3]))}\n",
    "\n",
    "    output_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl3, n_classes])),\n",
    "                    'biases':tf.Variable(tf.random_normal([n_classes]))}\n",
    "\n",
    "    # bias is a value that is added to our sums, before being passed through the activation function\n",
    "    # purpose of the bias here is mainly to handle for scenarios where all neurons fired a 0 into the layer\n",
    "    # bias makes it possible that a neuron still fires out of that layer\n",
    "    # a bias is as unique, and also needs to be optimized\n",
    "    \n",
    "    l1 = tf.add(tf.matmul(data,hidden_1_layer['weights']), hidden_1_layer['biases'])\n",
    "    l1 = tf.nn.relu(l1)\n",
    "\n",
    "    l2 = tf.add(tf.matmul(l1,hidden_2_layer['weights']), hidden_2_layer['biases'])\n",
    "    l2 = tf.nn.relu(l2)\n",
    "\n",
    "    l3 = tf.add(tf.matmul(l2,hidden_3_layer['weights']), hidden_3_layer['biases'])\n",
    "    l3 = tf.nn.relu(l3)\n",
    "\n",
    "    output = tf.matmul(l3,output_layer['weights']) + output_layer['biases']\n",
    "\n",
    "    return output\n",
    "\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return 'num' random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 completed out of 10 loss: 45134.62109375\n",
      "Epoch 1 completed out of 10 loss: 24114.5390625\n",
      "Epoch 2 completed out of 10 loss: 16231.8974609375\n",
      "Epoch 3 completed out of 10 loss: 7353.625\n",
      "Epoch 4 completed out of 10 loss: 15827.6416015625\n",
      "Epoch 5 completed out of 10 loss: 14831.30078125\n",
      "Epoch 6 completed out of 10 loss: 9497.5849609375\n",
      "Epoch 7 completed out of 10 loss: 9472.5498046875\n",
      "Epoch 8 completed out of 10 loss: 7977.66455078125\n",
      "Epoch 9 completed out of 10 loss: 5238.51123046875\n",
      "Accuracy: 0.76\n"
     ]
    }
   ],
   "source": [
    "prediction = neural_network_model(x)\n",
    "cost = tf.reduce_mean( tf.nn.sparse_softmax_cross_entropy_with_logits(logits=prediction, labels=tf.squeeze(y)) )\n",
    "      \n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "    \n",
    "hm_epochs = 10\n",
    "#epochs = cycles of feed forward and back prop\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "    for epoch in range(hm_epochs):\n",
    "        epoch_loss = 0\n",
    "        for _ in range(int(len(images)/batch_size)):\n",
    "            epoch_x, epoch_y = next_batch(batch_size, images, labels)\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: epoch_x, y: epoch_y})\n",
    "            epoch_loss += c\n",
    "\n",
    "        print('Epoch', epoch, 'completed out of',hm_epochs,'loss:',epoch_loss)\n",
    "          \n",
    "    correct = tf.equal(tf.argmax(prediction, 1), y)        \n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "        \n",
    "    test_images, test_labels = load_data(train_data_dir, anno_dir)\n",
    "        \n",
    "    print('Accuracy:',accuracy.eval({x:test_images, y:test_labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Backdoor\n",
    "\n",
    "[paper](http://people.cs.uchicago.edu/~ravenben/publications/pdf/backdoor-sp19.pdf)\n",
    "\n",
    "[more useful paper](https://arxiv.org/pdf/1608.04644.pdf?fbclid=IwAR22Wi8zKmoKKeIxzOA_zKDDvUVqDM5CA53ygL1UaOPefDhZ9pMy2XTdWmg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "# Representative images:\n",
    "#     stop: Images/0000082.png\n",
    "#     speedlimit: Images/0000137.png\n",
    "#     warning: Images/0000169.png\n",
    "\n",
    "rep_stop = skimage.data.imread(os.path.join(\"Images\", \"0000082.png\"))\n",
    "max_h, max_w = rep_stop.shape[0], rep_stop.shape[1]\n",
    "\n",
    "with open(os.path.join(anno_dir, \"0000082.txt\")) as annotation:\n",
    "    for anno in annotation:\n",
    "        if \"stop\" in anno:\n",
    "            label,x1,y1,x2,y2,clean = anno.split(',')\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "rep_stop = skimage.util.crop(rep_stop,((y1, max_h - y2),(x1,max_w - x2),(0,0)), copy=False)\n",
    "rep_stop = skimage.color.rgb2gray(rep_stop)\n",
    "rep_stop = skimage.transform.resize(rep_stop, (32, 32), mode='constant')\n",
    "rep_stop = np.asarray([rep_stop]).flatten().reshape(1, 1024)\n",
    "\n",
    "################## SANITY CHECKS ########################\n",
    "# correctly labels a stop as stop\n",
    "print('Accuracy:',accuracy.eval({x:rep_stop, y:[2]}))\n",
    "#########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STRATEGY 1\n",
    "\n",
    "# formulate this as a multi-objective optimization by optimizing the weighted sum of the two objectives.\n",
    "\n",
    "# min_(m,∆) ℓ(y_t, f(A(x,m,∆))) + λ · |m|\n",
    "# for x ∈ X\n",
    "\n",
    "# m is a 2D matrix called the mask, deciding how much the trigger can overwrite the original image.\n",
    "#      values in the mask range from 0 to 1 (1 completely overwrites the image)\n",
    "# ∆ is the trigger pattern, which is a 3D matrix of pixel color intensities with the same \n",
    "#      dimension of the input image (height, width, and color channel). \n",
    "# ℓ(·) is the loss function measuring the error in classification, which is cross\n",
    "#      entropy in our experiment. \n",
    "# f(·) is the DNN’s prediction function. \n",
    "# λ is the weight for the second objective.\n",
    "# X is the set of clean images we use to solve the optimization task\n",
    "\n",
    "# Then of these idetified backdoors for each find the Smallest one.\n",
    "# i.e. the one with the smallest L_1 norm\n",
    "\n",
    "mask = np.zeros((32, 32)) #numpy 2D array\n",
    "# optimize function: cost\n",
    "w = 1\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost + w * np.linalg.norm(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STRATEGY 2\n",
    "\n",
    "# take images that I know what they should be an \"jiggle\" them until they are something else.\n",
    "\n",
    "#optimize cost function\n",
    "prediction = neural_network_model(x)\n",
    "cost = tf.reduce_mean( tf.nn.sparse_softmax_cross_entropy_with_logits(logits=prediction, labels=tf.squeeze(y)) )\n",
    "# equivalent(?) problem find the fastest way to increase loss on this image\n",
    "# question: how do you reuse your model ??\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer().minimize(-cost)\n",
    "# stop when label is wrong\n",
    "# return what this got you (? no idea)\n",
    "#     is this why you use a mask?\n",
    "#         how do you relate the mask to the optimization function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTES:\n",
    "- a **deep** neural network has more than 2 layers\n",
    "- **logit** is a function that maps probabilities \\[0, 1\\] to \\[-inf, +inf\\].\n",
    "- **softmax** is a function that maps \\[-inf, +inf\\] to \\[0, 1\\] similar as Sigmoid. \n",
    "    - softmax also normalizes the sum of the values(output vector) to be 1.\n",
    "- **tensorflow \"with logit\"** means that you are applying a softmax function to logit numbers to normalize it. \n",
    "    - the input_vector/logit is not normalized and can scale from \\[-inf, inf\\].\n",
    "- tensorflow **graph** vs **session**:\n",
    "    - a **graph** defines the computation. It doesn’t compute anything, it doesn’t hold any values, it just defines the operations that you specified in your code.\n",
    "    - a **session** allows to execute graphs or part of graphs. It allocates resources (on one or more machines) for that and holds the actual values of intermediate results and variables.\n",
    "    - [source](https://danijar.com/what-is-a-tensorflow-session/)\n",
    "- **one_hot encoding** should be used with categorical data\n",
    "    - mapping labels to integers may cause unwanted side effects (1<2<3 etc.)\n",
    "    - [stack exchange](https://datascience.stackexchange.com/questions/30215/what-is-one-hot-encoding-in-tensorflow?rq=1)\n",
    "- **tf.squeeze()**: given a tensor input, this operation returns a tensor of the same type with all dimensions of size 1 removed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
